{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54131b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cc97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\", model_kwargs={\"device\": device}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4ef2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "pc = Pinecone()\n",
    "index = pc.Index(\"faqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011b5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2c9741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a6eaa7a5-9205-4d2b-b154-4f914c14213d', metadata={}, page_content='What should I do if I forget my password?\\nOn the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.'),\n",
       " Document(id='beb1f3e4-c611-4cb0-9af7-dacb4bfb7f69', metadata={}, page_content='What is the process for resolving login errors?\\nClear browser cache, try a different browser, or reset your password. If unresolved, email support@blucygnus.ai with error details.'),\n",
       " Document(id='5cc45301-13e3-4c02-9a2f-a46e011a2032', metadata={}, page_content='Can I revoke a team member’s access?\\nYes, in Team Settings, select the member, click Remove, and confirm to revoke their access instantly.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"forget password\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16372b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fd4a5bfa-07c3-41d1-8edf-81c4f3be9d5c', metadata={}, page_content='How do I handle sensitive data securely?\\nUse encryption settings, anonymize sensitive fields in Data Prep, and restrict access via RBAC to ensure security.'),\n",
       " Document(id='c8253c41-bc8e-474a-9e4d-23effa27d667', metadata={}, page_content='How do I ensure compliance with data regulations?\\nUse the platform’s GDPR and CCPA-compliant features, anonymize sensitive data, and consult the help center for compliance guides.'),\n",
       " Document(id='b163f733-56fa-4c70-9418-6da706625700', metadata={}, page_content='How do I secure my API key?\\nStore your API key securely, avoid sharing it publicly, and regenerate it in Developer Settings if compromised.'),\n",
       " Document(id='0cae8a28-2338-4560-a3d8-6586a5f1ae4f', metadata={}, page_content='How do I sign up for a live training webinar?\\nCheck the Events section in the dashboard or subscribe to the newsletter for webinar schedules and registration links.'),\n",
       " Document(id='bc289238-22e8-4a8e-a669-2568e55f3e81', metadata={}, page_content='How do I set up a dashboard for real-time monitoring?\\nCreate a dashboard, enable Real-Time Mode, connect to a live data source, and add widgets for continuous updates.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n",
    "retriever.invoke(\"how can i stay healthy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6c2087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='How do I handle sensitive data securely?\\nUse encryption settings, anonymize sensitive fields in Data Prep, and restrict access via RBAC to ensure security.'),\n",
       " Document(metadata={}, page_content='How do I sign up for a live training webinar?\\nCheck the Events section in the dashboard or subscribe to the newsletter for webinar schedules and registration links.'),\n",
       " Document(metadata={}, page_content='How do I troubleshoot upload errors?\\nCheck file format and size compatibility, ensure a stable internet connection, and review error messages. Contact support if issues persist.'),\n",
       " Document(metadata={}, page_content='How do I optimize dashboard performance for large teams?\\nLimit widgets, use cached data, and schedule updates during off-peak hours to ensure smooth performance for large teams.'),\n",
       " Document(metadata={}, page_content='How do I update my account information, like my name or organization?\\nIn the dashboard, navigate to Account Settings, edit fields like name or organization, and click Save to update your profile.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 5, \"lambda_mult\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"how can i stay healthy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607b0cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulti_query\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiQueryRetriever\n\u001b[32m      4\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mForget\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m llm = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_genai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m retriever_from_llm = MultiQueryRetriever.from_llm(\n\u001b[32m      7\u001b[39m     retriever=vector_store.as_retriever(\n\u001b[32m      8\u001b[39m         search_type=\u001b[33m\"\u001b[39m\u001b[33mmmr\u001b[39m\u001b[33m\"\u001b[39m, search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlambda_mult\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.5\u001b[39m}\n\u001b[32m      9\u001b[39m     ),\n\u001b[32m     10\u001b[39m     llm=llm,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:324\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m     warnings.warn(\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    321\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    330\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:381\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    383\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_fireworks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1531\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1524\u001b[39m         suggestion = (\n\u001b[32m   1525\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1526\u001b[39m         )\n\u001b[32m   1527\u001b[39m         logger.warning(\n\u001b[32m   1528\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1529\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1530\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1531\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1592\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1590\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m   1591\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1598\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1599\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py:286\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    273\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    279\u001b[39m     config = _prepare_config(\n\u001b[32m    280\u001b[39m         credentials=credentials,\n\u001b[32m    281\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m         client_info=client_info,\n\u001b[32m    285\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:698\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    689\u001b[39m     transport_init: Union[\n\u001b[32m    690\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    691\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    696\u001b[39m     )\n\u001b[32m    697\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    712\u001b[39m         std_logging.DEBUG\n\u001b[32m    713\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:234\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    229\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    230\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    231\u001b[39m             )\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    247\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:104\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    100\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    101\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/auth/_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "question = \"Forget\"\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type=\"mmr\", search_kwargs={\"k\": 4, \"lambda_mult\": 0.5}\n",
    "    ),\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d64f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52125519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e89e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688c774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b722506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\", model_kwargs={\"device\": device}\n",
    ")\n",
    "\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone()\n",
    "index = pc.Index(\"faqs\")\n",
    "\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type=\"mmr\", search_kwargs={\"k\": 4, \"lambda_mult\": 0.5}\n",
    "    ),\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"forget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7204903",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0af22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9010b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3663c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bab70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615c3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28e87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759992155.175896  270018 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759992171.745431  270018 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from support_hub.model_hub import get_model\n",
    "\n",
    "model = get_model()\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "pc = Pinecone()\n",
    "index = pc.Index(\"faqs\")\n",
    "import torch\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\", model_kwargs={\"device\": device}\n",
    ")\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "from support_hub.retriever_factory import create_multi_query_retriever\n",
    "\n",
    "retriever = create_multi_query_retriever(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a5ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='How do I handle slow dashboard loading times?\\nReduce dataset size, limit visualizations, or upgrade to a paid plan for faster processing. Contact support for persistent issues.'),\n",
       " Document(metadata={}, page_content='What is the benefit of automated anomaly detection?\\nAutomated anomaly detection identifies outliers in data (e.g., fraud, errors) without manual review, improving efficiency and accuracy.'),\n",
       " Document(metadata={}, page_content='Does the platform support voice commands?\\nVoice command support is in development and expected in a future release for hands-free operation.'),\n",
       " Document(metadata={}, page_content='What is the maximum number of saved queries?\\nThe free tier allows up to 20 saved queries; paid plans will offer higher limits post-launch.'),\n",
       " Document(metadata={}, page_content='Can I undo changes made during data preprocessing?\\nYes, the platform saves a version history in the Data Prep tool, allowing you to revert to previous dataset versions.'),\n",
       " Document(metadata={}, page_content='What should I do if I forget my password?\\nOn the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.'),\n",
       " Document(metadata={}, page_content='What is the automation trigger feature?\\nTriggers initiate workflows based on events, like new data uploads or time schedules, automating tasks like report generation or notifications.'),\n",
       " Document(metadata={}, page_content='How do I validate the accuracy of my predictive model?\\nIn the AI Models section, view the model’s performance metrics (e.g., RMSE, accuracy) and test it on a holdout dataset to ensure reliability.'),\n",
       " Document(metadata={}, page_content='What is the benefit of automated data cleaning?\\nAutomated data cleaning saves time by handling missing values, duplicates, or inconsistencies, ensuring high-quality data for analysis.'),\n",
       " Document(metadata={}, page_content='How do I monitor my usage limits?\\nCheck the Account Usage section in the dashboard for details on API calls, storage, and other metrics.'),\n",
       " Document(metadata={}, page_content='What is sentiment analysis, and how is it useful?\\nSentiment analysis evaluates text (e.g., reviews) to determine positive, negative, or neutral tones, helping businesses gauge customer satisfaction.'),\n",
       " Document(metadata={}, page_content='Can I customize AI model parameters?\\nAdvanced users can adjust parameters like learning rate or epochs in the AI Models section via the API or scripting tools.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"forget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25e1bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\nUse three sentences maximum and keep the answer as concise as possible.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83b57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87196f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff80e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521767d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666daf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12986bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b6040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19dad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a26a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow can I reset my password?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2657\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2656\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2657\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2664\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2666\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2667\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(state: State):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# retrieved_docs = vector_store.similarity_search(state[\"question\"])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     retrieved_docs = \u001b[43mcreate_multi_query_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRetrieved docs:\u001b[39m\u001b[33m\"\u001b[39m, retrieved_docs)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: retrieved_docs}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/support_hub/retriever_factory.py:61\u001b[39m, in \u001b[36mcreate_multi_query_retriever\u001b[39m\u001b[34m(vector_store, model_name, model_provider, k, lambda_mult)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_multi_query_retriever\u001b[39m(\n\u001b[32m     43\u001b[39m     vector_store: VectorStore,\n\u001b[32m     44\u001b[39m     model_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     lambda_mult: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.5\u001b[39m,\n\u001b[32m     48\u001b[39m ) -> MultiQueryRetriever:\n\u001b[32m     49\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create multi-query retriever with LLM.\u001b[39;00m\n\u001b[32m     50\u001b[39m \n\u001b[32m     51\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m \u001b[33;03m        Configured multi-query retriever\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     llm = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     base_retriever = create_mmr_retriever(vector_store, k, lambda_mult)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m MultiQueryRetriever.from_llm(retriever=base_retriever, llm=llm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:324\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m     warnings.warn(\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    321\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    330\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:381\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    383\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_fireworks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1531\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1524\u001b[39m         suggestion = (\n\u001b[32m   1525\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1526\u001b[39m         )\n\u001b[32m   1527\u001b[39m         logger.warning(\n\u001b[32m   1528\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1529\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1530\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1531\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1592\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1590\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m   1591\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1598\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1599\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py:286\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    273\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    279\u001b[39m     config = _prepare_config(\n\u001b[32m    280\u001b[39m         credentials=credentials,\n\u001b[32m    281\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m         client_info=client_info,\n\u001b[32m    285\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:698\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    689\u001b[39m     transport_init: Union[\n\u001b[32m    690\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    691\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    696\u001b[39m     )\n\u001b[32m    697\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    712\u001b[39m         std_logging.DEBUG\n\u001b[32m    713\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:234\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    229\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    230\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    231\u001b[39m             )\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    247\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:104\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    100\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    101\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/google/auth/_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "During task with name 'retrieve' and id 'bf96e5ab-d85c-b53e-58c3-3c8d7538359d'"
     ]
    }
   ],
   "source": [
    "graph.invoke({\"question\": \"How can I reset my password?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27153cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069edda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4f873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a551e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abef305",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ai (3.12.11) (Python 3.12.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"ff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75884b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759297795.171370  464243 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da867596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c10157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "a = llm.invoke(f\"i forget password you are bad person\\n out should be in {Classification.model_json_schema()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf09a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"sentiment\": \"sad\",\n",
      "  \"aggressiveness\": 5,\n",
      "  \"language\": \"english\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(a.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc5dc15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='sad', aggressiveness=5, language='english')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification(**{\n",
    "  \"sentiment\": \"sad\",\n",
    "  \"aggressiveness\": 5,\n",
    "  \"language\": \"english\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e142ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa296b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fe7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74478819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759737521.519817 2987278 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Desktop_Login_Issue', 93.94)\n",
      "Priority.VeryHigh\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "# from langchain.output_parsers import EnumOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from pydantic import BaseModel, Field, conint\n",
    "\n",
    "\n",
    "class CategoriesProbabilities(BaseModel):\n",
    "    Desktop: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket relates to general desktop issues, including software, settings, or performance.\",\n",
    "    )\n",
    "    Desktop_Application: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is about problems with installed desktop applications (e.g., MS Office, browsers).\",\n",
    "    )\n",
    "    Desktop_Asset_Management: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket concerns desktop asset tracking, inventory, or allocation.\",\n",
    "    )\n",
    "    Desktop_Hardware: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is related to physical hardware issues such as monitor, keyboard, or peripherals.\",\n",
    "    )\n",
    "    Desktop_Login_Issue: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is about desktop login problems, like incorrect credentials or account lockouts.\",\n",
    "    )\n",
    "    Desktop_Storage: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket involves local storage issues, such as low disk space or drive access problems.\",\n",
    "    )\n",
    "\n",
    "    Email: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket relates to general email issues, including access, sync, or configuration problems.\",\n",
    "    )\n",
    "    Email_Email_Create: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is a request to create a new company email ID or mailbox.\",\n",
    "    )\n",
    "    Email_Whitelist_Email: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket requests to whitelist an email address or domain to prevent blocking or spam issues.\",\n",
    "    )\n",
    "\n",
    "    Internet: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket relates to internet connectivity issues, such as no access, slow speed, or frequent disconnections.\",\n",
    "    )\n",
    "    Network: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket involves internal network problems, including LAN/Wi-Fi issues or access to shared resources.\",\n",
    "    )\n",
    "    International_Calling: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket relates to enabling, disabling, or troubleshooting international calling services.\",\n",
    "    )\n",
    "\n",
    "    Server: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is about general server-related issues or requests not covered by subcategories.\",\n",
    "    )\n",
    "    Server_Application: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket concerns applications hosted on servers, including downtime or access errors.\",\n",
    "    )\n",
    "    Server_Client_Servers: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket relates to client-specific servers, configurations, or deployment problems.\",\n",
    "    )\n",
    "\n",
    "    Storage: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket involves shared or cloud storage issues (e.g., OneDrive, NAS, shared drives).\",\n",
    "    )\n",
    "    Printing: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is about printing issues, such as printer detection, queue errors, or print quality problems.\",\n",
    "    )\n",
    "\n",
    "    Website_Blocked: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket requests access to a blocked website or restricted web content.\",\n",
    "    )\n",
    "    New_Service_Request: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is a request for a new IT service, software installation, or hardware provisioning.\",\n",
    "    )\n",
    "\n",
    "    CSG_PDG: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket is related to Corporate Services Group – Product Development Group internal tools or systems.\",\n",
    "    )\n",
    "    Others: float = Field(\n",
    "        ...,\n",
    "        description=\"Probability that the ticket does not fall into any predefined categories and needs manual review or reassignment.\",\n",
    "    )\n",
    "\n",
    "    def top_category(self) -> tuple[str, float]:\n",
    "        data = self.model_dump()  # Pydantic v2\n",
    "        return max(data.items(), key=lambda kv: kv[1])\n",
    "\n",
    "\n",
    "class Priority(Enum):\n",
    "    VeryHigh = 1\n",
    "    High = 2\n",
    "    Normal = 3\n",
    "    Low = 4\n",
    "    VeryLow = 5\n",
    "\n",
    "\n",
    "class TicketPrediction(BaseModel):\n",
    "    categories_probabilities: CategoriesProbabilities = Field(\n",
    "        ..., description=\"Probability scores for each ticket category.\"\n",
    "    )\n",
    "    priority: Priority = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Priority of the ticket, from 1 to 5:\\n\"\n",
    "            \"1 = Very High\\n\"\n",
    "            \"2 = High\\n\"\n",
    "            \"3 = Normal\\n\"\n",
    "            \"4 = Low\\n\"\n",
    "            \"5 = Very Low\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=TicketPrediction)\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an IT support ticket classifier.\n",
    "\n",
    "Given the ticket description, provide the following:\n",
    "\n",
    "1. **categories_probabilities**: a probability score (in percentage) for each ticket category that represents how likely the ticket belongs to that category.\n",
    "   - All probabilities must sum up to 100%.\n",
    "   - No two categories should have the same probability score.\n",
    "\n",
    "2. **priority**: one of the following Enum values (VeryHigh = 1, High = 2, Normal = 3, Low = 4, VeryLow = 5), representing how important it is to resolve the issue quickly so that there are no work blockers or wasted time.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Ticket Description:\n",
    "\"{query}\"\n",
    "\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    # partial_variables={\"format_instructions\": new_parser.get_format_instructions()},\n",
    "    partial_variables={\"format_instructions\": new_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"my active directory is locked\"})\n",
    "opt = parser.invoke(output)\n",
    "print(opt.categories_probabilities.top_category())\n",
    "print(opt.priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7125ed16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Desktop_Login_Issue', 93.94)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.categories_probabilities.top_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7589eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an IT support ticket classifier.\n",
      "\n",
      "Given the ticket description, provide the following:\n",
      "\n",
      "1. **categories_probabilities**: a probability score (in percentage) for each ticket category that represents how likely the ticket belongs to that category.\n",
      "   - All probabilities must sum up to 100%.\n",
      "   - No two categories should have the same probability score.\n",
      "\n",
      "2. **priority**: one of the following Enum values (VeryHigh = 1, High = 2, Normal = 3, Low = 4, VeryLow = 5), representing how important it is to resolve the issue quickly so that there are no work blockers or wasted time.\n",
      "\n",
      "Output the result in JSON format compatible with the `TicketPrediction` Pydantic model.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"CategoriesProbabilities\": {\"properties\": {\"Desktop\": {\"description\": \"Probability that the ticket relates to general desktop issues, including software, settings, or performance.\", \"title\": \"Desktop\", \"type\": \"number\"}, \"Desktop_Application\": {\"description\": \"Probability that the ticket is about problems with installed desktop applications (e.g., MS Office, browsers).\", \"title\": \"Desktop Application\", \"type\": \"number\"}, \"Desktop_Asset_Management\": {\"description\": \"Probability that the ticket concerns desktop asset tracking, inventory, or allocation.\", \"title\": \"Desktop Asset Management\", \"type\": \"number\"}, \"Desktop_Hardware\": {\"description\": \"Probability that the ticket is related to physical hardware issues such as monitor, keyboard, or peripherals.\", \"title\": \"Desktop Hardware\", \"type\": \"number\"}, \"Desktop_Login_Issue\": {\"description\": \"Probability that the ticket is about desktop login problems, like incorrect credentials or account lockouts.\", \"title\": \"Desktop Login Issue\", \"type\": \"number\"}, \"Desktop_Storage\": {\"description\": \"Probability that the ticket involves local storage issues, such as low disk space or drive access problems.\", \"title\": \"Desktop Storage\", \"type\": \"number\"}, \"Email\": {\"description\": \"Probability that the ticket relates to general email issues, including access, sync, or configuration problems.\", \"title\": \"Email\", \"type\": \"number\"}, \"Email_Email_Create\": {\"description\": \"Probability that the ticket is a request to create a new company email ID or mailbox.\", \"title\": \"Email Email Create\", \"type\": \"number\"}, \"Email_Whitelist_Email\": {\"description\": \"Probability that the ticket requests to whitelist an email address or domain to prevent blocking or spam issues.\", \"title\": \"Email Whitelist Email\", \"type\": \"number\"}, \"Internet\": {\"description\": \"Probability that the ticket relates to internet connectivity issues, such as no access, slow speed, or frequent disconnections.\", \"title\": \"Internet\", \"type\": \"number\"}, \"Network\": {\"description\": \"Probability that the ticket involves internal network problems, including LAN/Wi-Fi issues or access to shared resources.\", \"title\": \"Network\", \"type\": \"number\"}, \"International_Calling\": {\"description\": \"Probability that the ticket relates to enabling, disabling, or troubleshooting international calling services.\", \"title\": \"International Calling\", \"type\": \"number\"}, \"Server\": {\"description\": \"Probability that the ticket is about general server-related issues or requests not covered by subcategories.\", \"title\": \"Server\", \"type\": \"number\"}, \"Server_Application\": {\"description\": \"Probability that the ticket concerns applications hosted on servers, including downtime or access errors.\", \"title\": \"Server Application\", \"type\": \"number\"}, \"Server_Client_Servers\": {\"description\": \"Probability that the ticket relates to client-specific servers, configurations, or deployment problems.\", \"title\": \"Server Client Servers\", \"type\": \"number\"}, \"Storage\": {\"description\": \"Probability that the ticket involves shared or cloud storage issues (e.g., OneDrive, NAS, shared drives).\", \"title\": \"Storage\", \"type\": \"number\"}, \"Printing\": {\"description\": \"Probability that the ticket is about printing issues, such as printer detection, queue errors, or print quality problems.\", \"title\": \"Printing\", \"type\": \"number\"}, \"Website_Blocked\": {\"description\": \"Probability that the ticket requests access to a blocked website or restricted web content.\", \"title\": \"Website Blocked\", \"type\": \"number\"}, \"New_Service_Request\": {\"description\": \"Probability that the ticket is a request for a new IT service, software installation, or hardware provisioning.\", \"title\": \"New Service Request\", \"type\": \"number\"}, \"CSG_PDG\": {\"description\": \"Probability that the ticket is related to Corporate Services Group – Product Development Group internal tools or systems.\", \"title\": \"Csg Pdg\", \"type\": \"number\"}, \"Others\": {\"description\": \"Probability that the ticket does not fall into any predefined categories and needs manual review or reassignment.\", \"title\": \"Others\", \"type\": \"number\"}}, \"required\": [\"Desktop\", \"Desktop_Application\", \"Desktop_Asset_Management\", \"Desktop_Hardware\", \"Desktop_Login_Issue\", \"Desktop_Storage\", \"Email\", \"Email_Email_Create\", \"Email_Whitelist_Email\", \"Internet\", \"Network\", \"International_Calling\", \"Server\", \"Server_Application\", \"Server_Client_Servers\", \"Storage\", \"Printing\", \"Website_Blocked\", \"New_Service_Request\", \"CSG_PDG\", \"Others\"], \"title\": \"CategoriesProbabilities\", \"type\": \"object\"}, \"Priority\": {\"enum\": [1, 2, 3, 4, 5], \"title\": \"Priority\", \"type\": \"integer\"}}, \"properties\": {\"categories_probabilities\": {\"$ref\": \"#/$defs/CategoriesProbabilities\", \"description\": \"Probability scores for each ticket category.\"}, \"priority\": {\"$ref\": \"#/$defs/Priority\", \"description\": \"Priority of the ticket, from 1 to 5:\\n1 = Very High\\n2 = High\\n3 = Normal\\n4 = Low\\n5 = Very Low\"}}, \"required\": [\"categories_probabilities\", \"priority\"]}\n",
      "```\n",
      "\n",
      "Ticket Description:\n",
      "\"it is very good  my  bloody son.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke({\"query\": \"it is very good  my  bloody son.\"}).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc14148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759818928.521625 3489210 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759818928.543623 3489210 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ticket_class': {'service': {'service_name': '', 'service_id': '2'},\n",
       "  'role': 'cloud engineer',\n",
       "  'type': {'type_name': '', 'type_id': '5'}},\n",
       " 'priority': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from support_hub.ticket_classifier.ticket_classification import run_ticket_classification\n",
    "\n",
    "await run_ticket_classification(\"create new s3 bucket for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b21758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759818907.220970 3489210 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759818907.267192 3489210 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ticket_class': {'service': {'service_name': 'Desktop Login',\n",
       "   'service_id': '18'},\n",
       "  'role': 'Manager',\n",
       "  'type': {'type_name': '', 'type_id': '5'}},\n",
       " 'priority': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from support_hub.ticket_classifier.ticket_classification import run_ticket_classification\n",
    "\n",
    "await run_ticket_classification(\"my active directory is locked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ff3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10ea72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': True, 'status_code': 200, 'message': 'List fetched successfully', 'data': [{'role': 'Computer Hardware Engineer'}, {'role': 'Linux Admin'}, {'role': 'Manager'}, {'role': 'cloud engineer'}]}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "\n",
    "async def fetch_skills(session, base_url):\n",
    "    \"\"\"\n",
    "    Asynchronously fetch skills data from the API endpoint.\n",
    "    \n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): The aiohttp session for making requests.\n",
    "        base_url (str): The base URL of the API (e.g., 'http://example.com').\n",
    "    \n",
    "    Returns:\n",
    "        dict: The parsed JSON response.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/skills/\"\n",
    "    async with session.get(url) as response:\n",
    "        # if response.status == 200:\n",
    "            return await response.json()\n",
    "        # else:\n",
    "        #     raise Exception(f\"Failed to fetch data: HTTP {response.status}\")\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "       \n",
    "            data = await fetch_skills(session, \"http://192.168.71.115\")\n",
    "            print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9fd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roles': ['Computer Hardware Engineer',\n",
       "  'Linux Admin',\n",
       "  'Manager',\n",
       "  'cloud engineer']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aiohttp\n",
    "\n",
    "async def fetch_roles(session, base_url):\n",
    "    \"\"\"\n",
    "    Asynchronously fetch skills data from the API endpoint.\n",
    "    \n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): The aiohttp session for making requests.\n",
    "        base_url (str): The base URL of the API (e.g., 'http://example.com').\n",
    "    \n",
    "    Returns:\n",
    "        dict: The parsed JSON response.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/skills/\"\n",
    "    async with session.get(url) as response:\n",
    "        if response.status == 200:\n",
    "            return await response.json()\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch data: HTTP {response.status}\")\n",
    "\n",
    "async def list_roles():\n",
    "    base_url = \"http://192.168.71.115\"  # Replace with your actual base URL\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            data = await fetch_roles(session, base_url)\n",
    "            # Example: Access the roles\n",
    "            roles = [item[\"role\"] for item in data[\"data\"]]\n",
    "            return {\"roles\": roles}\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "await list_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b6d6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = await list_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67b5d780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roles': ['Computer Hardware Engineer',\n",
       "  'Linux Admin',\n",
       "  'Manager',\n",
       "  'cloud engineer']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dffdfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roles': ['Computer Hardware Engineer',\n",
       "  'Linux Admin',\n",
       "  'Manager',\n",
       "  'cloud engineer']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aiohttp\n",
    "\n",
    "\n",
    "class RoleFetcher:\n",
    "    \"\"\"\n",
    "    A class to asynchronously fetch roles from the API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str = \"http://192.168.71.115\"):\n",
    "        \"\"\"\n",
    "        Initialize the RoleFetcher with the base URL of the API.\n",
    "\n",
    "        Args:\n",
    "            base_url (str): The base URL of the API (e.g., 'http://192.168.71.115').\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "\n",
    "    async def fetch_roles(self):\n",
    "        \"\"\"\n",
    "        Asynchronously fetch roles from the API endpoint.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the list of roles.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the API request fails.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/api/skills/\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    roles = [item[\"role\"] for item in data[\"data\"]]\n",
    "                    return {\"roles\": roles}\n",
    "                else:\n",
    "                    raise Exception(f\"Failed to fetch data: HTTP {response.status}\")\n",
    "\n",
    "    async def list_roles(self):\n",
    "        \"\"\"\n",
    "        Asynchronously list roles from the API.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the list of roles.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the API request fails.\n",
    "        \"\"\"\n",
    "        return await self.fetch_roles()\n",
    "\n",
    "\n",
    "fetcher = RoleFetcher()\n",
    "\n",
    "await fetcher.list_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0f013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from support_hub.ticket_classifier.models.utils import RoleFetcher\n",
    "\n",
    "\n",
    "async def get_roles():\n",
    "    fetcher = RoleFetcher()\n",
    "    try:\n",
    "        result = await fetcher.list_roles()\n",
    "        return result.get(\"roles\", [])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "a = await get_roles()\n",
    "\n",
    "class Roles(BaseModel):\n",
    "    role_names: list[str] = Field(default=a, description=\"Names of the roles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15122592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roles(role_names=['Computer Hardware Engineer', 'Linux Admin', 'Manager', 'cloud engineer'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Roles(role_names=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a54397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Literal[['i', 'am', 'sourabh']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaae3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from support_hub.ticket_classifier.parsers.output_parsers import get_pydantic_role_parser\n",
    "\n",
    "p = get_pydantic_role_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79a56fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an IT support ticket classifier.\n",
      "\n",
      "Given the ticket, provide the following:\n",
      "\n",
      "role: a single resolver role to assign this ticket to.\n",
      "   - Return exactly one string that matches character-for-character one of the provided roles.\n",
      "   - Do not invent or modify role names.\n",
      "   - If multiple roles could apply, choose the most specialized technical role aligned with the primary action implied by the ticket.\n",
      "   - If unable to confidently select an exact match from the provided roles, return \"Manager\" by default.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Roles\": {\"enum\": [\"Computer Hardware Engineer\", \"Linux Admin\", \"Manager\", \"cloud engineer\"], \"title\": \"Roles\", \"type\": \"string\"}}, \"properties\": {\"role_name\": {\"$ref\": \"#/$defs/Roles\", \"description\": \"Name of the role\"}}, \"required\": [\"role_name\"]}\n",
      "```\n",
      "\n",
      "Ticket:\n",
      "```\n",
      "my active directory is locked\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from support_hub.ticket_classifier.prompts.ticket_prompt import get_ticket_classification_prompt_roles\n",
    "\n",
    "print(get_ticket_classification_prompt_roles(p.get_format_instructions()).invoke({\"ticket\": \"my active directory is locked\"}).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed915ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c01d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760004043.201021  341234 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n",
      "E0000 00:00:1760004063.078721  341658 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760004073.743023  341234 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760004073.749955  341234 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "On the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from support_hub.model_hub import get_model\n",
    "from support_hub.retriever_factory import create_multi_query_retriever\n",
    "\n",
    "llm = get_model()\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\", model_kwargs={\"device\": device}\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "pc = Pinecone()\n",
    "index = pc.Index(\"faqs\")\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    answer_found: bool\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    # retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    retrieved_docs = create_multi_query_retriever(vector_store=vector_store).invoke(\n",
    "        state[\"question\"]\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "from support_hub.context_evaluateor import evaluate_relevance\n",
    "\n",
    "\n",
    "async def generate(state: State):\n",
    "    docs_content = (\n",
    "        \"\\n```\\n\" + \"\\n\\n\".join(doc.page_content for doc in state[\"context\"]) + \"\\n```\"\n",
    "    )\n",
    "    # print(docs_content)\n",
    "\n",
    "    evaluated_class = await evaluate_relevance(\n",
    "        query=state[\"question\"], retrieved_context=docs_content\n",
    "    )\n",
    "    # print(\"end=  \", evaluated_class.get(\"reason\"))\n",
    "    if evaluated_class.get(\"is_relevant\") is False:\n",
    "        return {\"answer_found\": False}\n",
    "\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer_found\": True, \"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "answer = await graph.ainvoke({\"question\": \"How can I reset my password??\"})\n",
    "print(answer.get(\"answer_found\"))\n",
    "if answer.get(\"answer_found\"):\n",
    "    print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following are the retrieved context. give answer according to these context only\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68b973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759993889.577935  278591 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```\n",
      "What should I do if I forget my password?\n",
      "On the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.\n",
      "\n",
      "How do I recover a deleted dashboard?\n",
      "Deleted dashboards cannot be recovered unless previously exported. Contact support within 30 days for possible data restoration.\n",
      "\n",
      "How do I enable two-factor authentication (2FA)?\n",
      "In Account Settings, select Security, enable 2FA, and follow the prompts to link your phone or authenticator app for added login protection.\n",
      "\n",
      "Can I change my email address after signing up?\n",
      "Yes, go to Account Settings in the dashboard, select Change Email, enter a new email, and verify it via a confirmation link sent to the new address.\n",
      "\n",
      "Can I revoke a team member’s access?\n",
      "Yes, in Team Settings, select the member, click Remove, and confirm to revoke their access instantly.\n",
      "\n",
      "What happens if my payment fails?\n",
      "You will receive an email notification to update your payment method. Access Billing in the dashboard to add a new card or retry payment to avoid service interruption.\n",
      "\n",
      "How do I upgrade from a free to a paid plan?\n",
      "Once the live site launches, go to the Account Settings or Billing section in your dashboard, select the desired paid plan, and follow the prompts to enter payment information. Your account will upgrade instantly, granting access to premium features.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "answer = graph.invoke({\"question\": \"How can I reset my password?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64156540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='What should I do if I forget my password?\\nOn the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.'),\n",
       " Document(metadata={}, page_content='How do I recover a deleted dashboard?\\nDeleted dashboards cannot be recovered unless previously exported. Contact support within 30 days for possible data restoration.'),\n",
       " Document(metadata={}, page_content='How do I enable two-factor authentication (2FA)?\\nIn Account Settings, select Security, enable 2FA, and follow the prompts to link your phone or authenticator app for added login protection.'),\n",
       " Document(metadata={}, page_content='Can I change my email address after signing up?\\nYes, go to Account Settings in the dashboard, select Change Email, enter a new email, and verify it via a confirmation link sent to the new address.'),\n",
       " Document(metadata={}, page_content='Can I revoke a team member’s access?\\nYes, in Team Settings, select the member, click Remove, and confirm to revoke their access instantly.'),\n",
       " Document(metadata={}, page_content='What happens if my payment fails?\\nYou will receive an email notification to update your payment method. Access Billing in the dashboard to add a new card or retry payment to avoid service interruption.'),\n",
       " Document(metadata={}, page_content='How do I upgrade from a free to a paid plan?\\nOnce the live site launches, go to the Account Settings or Billing section in your dashboard, select the desired paid plan, and follow the prompts to enter payment information. Your account will upgrade instantly, granting access to premium features.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc6ba62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email; click it, create a new password, and log in.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dac286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f350aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3551d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5877d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc4012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700896c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760004999.148640  347204 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005002.063027  347638 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005012.328599  347204 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005012.335920  347204 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_found': False, 'answer': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langgraph.graph import START, StateGraph\n",
    "from pinecone import Pinecone\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from support_hub.context_evaluateor import evaluate_relevance\n",
    "from support_hub.model_hub import get_model\n",
    "from support_hub.retriever_factory import create_multi_query_retriever\n",
    "\n",
    "\n",
    "# State definition\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"State schema for RAG pipeline.\"\"\"\n",
    "\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    answer_found: bool\n",
    "\n",
    "\n",
    "class RAGConfig:\n",
    "    \"\"\"Configuration for RAG pipeline components.\"\"\"\n",
    "\n",
    "    # Prompt template\n",
    "    ANSWER_TEMPLATE = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Embedding model configuration\n",
    "    EMBEDDING_MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "    # Pinecone configuration\n",
    "    PINECONE_INDEX_NAME = \"faqs\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_model_name: Optional[str] = None,\n",
    "        pinecone_index_name: Optional[str] = None,\n",
    "        answer_template: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize RAG configuration.\n",
    "\n",
    "        Args:\n",
    "            embedding_model_name: Name of HuggingFace embedding model.\n",
    "            pinecone_index_name: Name of Pinecone index.\n",
    "            answer_template: Custom prompt template for answer generation.\n",
    "        \"\"\"\n",
    "        self.embedding_model_name = embedding_model_name or self.EMBEDDING_MODEL_NAME\n",
    "        self.pinecone_index_name = pinecone_index_name or self.PINECONE_INDEX_NAME\n",
    "        self.answer_template = answer_template or self.ANSWER_TEMPLATE\n",
    "\n",
    "\n",
    "class RAGPipeline:\n",
    "    \"\"\"End-to-end RAG pipeline using LangGraph.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: Optional[VectorStore] = None,\n",
    "        llm: Optional[BaseLanguageModel] = None,\n",
    "        config: Optional[RAGConfig] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize RAG pipeline.\n",
    "\n",
    "        Args:\n",
    "            vector_store: Vector store for document retrieval. If None, creates Pinecone store.\n",
    "            llm: Language model for generation. If None, uses default from model_hub.\n",
    "            config: RAG configuration. If None, uses default configuration.\n",
    "        \"\"\"\n",
    "        self.config = config or RAGConfig()\n",
    "        self.llm = llm or get_model()\n",
    "        self.vector_store = vector_store or self._create_default_vector_store()\n",
    "        self.prompt = PromptTemplate.from_template(self.config.answer_template)\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "    def _create_default_vector_store(self) -> VectorStore:\n",
    "        \"\"\"Create default Pinecone vector store with HuggingFace embeddings.\"\"\"\n",
    "        load_dotenv()\n",
    "\n",
    "        # Set device for embeddings\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Initialize embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=self.config.embedding_model_name, model_kwargs={\"device\": device}\n",
    "        )\n",
    "\n",
    "        # Initialize Pinecone\n",
    "        pc = Pinecone()\n",
    "        index = pc.Index(self.config.pinecone_index_name)\n",
    "\n",
    "        return PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "    def _retrieve(self, state: RAGState) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for the question.\n",
    "\n",
    "        Args:\n",
    "            state: Current RAG state.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with retrieved context documents.\n",
    "        \"\"\"\n",
    "        retriever = create_multi_query_retriever(vector_store=self.vector_store)\n",
    "        retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "        return {\"context\": retrieved_docs}\n",
    "\n",
    "    async def _generate(self, state: RAGState) -> dict:\n",
    "        \"\"\"\n",
    "        Generate answer from retrieved context.\n",
    "\n",
    "        Args:\n",
    "            state: Current RAG state with retrieved context.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with answer_found flag and answer content.\n",
    "        \"\"\"\n",
    "        # Format context documents\n",
    "        docs_content = (\n",
    "            \"\\n```\"\n",
    "            + \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "            + \"\\n```\"\n",
    "        )\n",
    "\n",
    "        # Evaluate context relevance\n",
    "        evaluated_class = await evaluate_relevance(\n",
    "            query=state[\"question\"], retrieved_context=docs_content\n",
    "        )\n",
    "\n",
    "        # Return early if context is not relevant\n",
    "        if not evaluated_class.get(\"is_relevant\"):\n",
    "            return {\"answer_found\": False}\n",
    "\n",
    "        # Generate answer\n",
    "        messages = self.prompt.invoke(\n",
    "            {\"question\": state[\"question\"], \"context\": docs_content}\n",
    "        )\n",
    "        response = self.llm.invoke(messages)\n",
    "\n",
    "        return {\"answer_found\": True, \"answer\": response.content}\n",
    "\n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"\n",
    "        Build LangGraph pipeline.\n",
    "\n",
    "        Returns:\n",
    "            Compiled StateGraph for RAG pipeline.\n",
    "        \"\"\"\n",
    "        graph_builder = StateGraph(RAGState).add_sequence(\n",
    "            [self._retrieve, self._generate]\n",
    "        )\n",
    "        graph_builder.add_edge(START, \"_retrieve\")\n",
    "        return graph_builder.compile()\n",
    "\n",
    "    async def ainvoke(self, question: str) -> dict:\n",
    "        \"\"\"\n",
    "        Asynchronously invoke RAG pipeline.\n",
    "\n",
    "        Args:\n",
    "            question: User question to answer.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing answer_found flag and answer content.\n",
    "        \"\"\"\n",
    "        result = await self.graph.ainvoke({\"question\": question})\n",
    "        return {\n",
    "            \"answer_found\": result.get(\"answer_found\", False),\n",
    "            \"answer\": result.get(\"answer\"),\n",
    "        }\n",
    "\n",
    "    def invoke(self, question: str) -> dict:\n",
    "        \"\"\"\n",
    "        Synchronously invoke RAG pipeline.\n",
    "\n",
    "        Args:\n",
    "            question: User question to answer.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing answer_found flag and answer content.\n",
    "        \"\"\"\n",
    "        result = self.graph.invoke({\"question\": question})\n",
    "        return {\n",
    "            \"answer_found\": result.get(\"answer_found\", False),\n",
    "            \"answer\": result.get(\"answer\"),\n",
    "        }\n",
    "\n",
    "    async def stream(self, question: str):\n",
    "        \"\"\"\n",
    "        Stream RAG pipeline execution with intermediate states.\n",
    "\n",
    "        Args:\n",
    "            question: User question to answer.\n",
    "\n",
    "        Yields:\n",
    "            Intermediate states during pipeline execution.\n",
    "        \"\"\"\n",
    "        async for state in self.graph.astream({\"question\": question}):\n",
    "            yield state\n",
    "\n",
    "\n",
    "# Factory function for easy instantiation\n",
    "async def create_rag_pipeline(\n",
    "    ticket: str,\n",
    "    vector_store: Optional[VectorStore] = None,\n",
    "    llm: Optional[BaseLanguageModel] = None,\n",
    "    config: Optional[RAGConfig] = None,\n",
    ") -> RAGPipeline:\n",
    "    \"\"\"\n",
    "    Create a RAG pipeline instance.\n",
    "\n",
    "    Args:\n",
    "        vector_store: Custom vector store. If None, uses default Pinecone.\n",
    "        llm: Custom language model. If None, uses default from model_hub.\n",
    "        config: Custom RAG configuration. If None, uses defaults.\n",
    "\n",
    "    Returns:\n",
    "        Configured RAGPipeline instance.\n",
    "    \"\"\"\n",
    "    pipeline = RAGPipeline(vector_store=vector_store, llm=llm, config=config)\n",
    "    result = await pipeline.ainvoke(ticket)\n",
    "    return {\"answer_found\": result.get(\"answer_found\"), \"answer\": result.get(\"answer\")}\n",
    "\n",
    "\n",
    "# Create pipeline with defaults\n",
    "pipeline = await create_rag_pipeline(\"my active directory is locked\")\n",
    "\n",
    "# # Get answer\n",
    "# result = await pipeline.ainvoke(\"hahaha\")\n",
    "\n",
    "# if result[\"answer_found\"]:\n",
    "#     print(f\"Answer: {result['answer']}\")\n",
    "# else:\n",
    "#     print(\"No relevant answer found in knowledge base.\")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979d4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aba02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e8fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33c8347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sourabh_critical/ids-hackathon/backend/ai/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760005360.209106  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005362.110183  350509 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005379.193997  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005379.200689  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_found': False, 'answer': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from support_hub.rag_pipeline import create_rag_pipeline\n",
    "await create_rag_pipeline(\"my active directory is locked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a42e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760005399.162025  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005399.180802  350509 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005410.652202  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760005410.658970  350032 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_found': True,\n",
       " 'answer': 'On the login page at https://staging.blucygnus.ai/, click Forgot Password, enter your registered email, and submit. You will receive a reset link in your email. Click it, create a new password, and log in.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await create_rag_pipeline(\"i forget my password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097043ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
